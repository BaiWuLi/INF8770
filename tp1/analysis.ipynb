{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b738c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import heapq\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Huffman coding\n",
    "# -----------------------------\n",
    "class HuffmanNode:\n",
    "    def __init__(self, char, freq):\n",
    "        self.char = char\n",
    "        self.freq = freq\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.freq < other.freq\n",
    "\n",
    "def huffman_encode(text):\n",
    "    freq = collections.Counter(text)\n",
    "    heap = [HuffmanNode(ch, f) for ch, f in freq.items()]\n",
    "    heapq.heapify(heap)\n",
    "\n",
    "    while len(heap) > 1:\n",
    "        n1 = heapq.heappop(heap)\n",
    "        n2 = heapq.heappop(heap)\n",
    "        merged = HuffmanNode(None, n1.freq + n2.freq)\n",
    "        merged.left, merged.right = n1, n2\n",
    "        heapq.heappush(heap, merged)\n",
    "\n",
    "    codes = {}\n",
    "    def generate_codes(node, current=\"\"):\n",
    "        if node is None:\n",
    "            return\n",
    "        if node.char is not None:\n",
    "            codes[node.char] = current\n",
    "        generate_codes(node.left, current + \"0\")\n",
    "        generate_codes(node.right, current + \"1\")\n",
    "    generate_codes(heap[0])\n",
    "\n",
    "    encoded = \"\".join(codes[ch] for ch in text)\n",
    "    return encoded, codes\n",
    "\n",
    "def huffman_encode_words(text):\n",
    "    # Tokeniser par mots\n",
    "    words = text.split()  # Par défaut, séparation sur les espaces\n",
    "\n",
    "    # Calculer la fréquence des mots\n",
    "    freq = collections.Counter(words)\n",
    "\n",
    "    # Créer les feuilles de l'arbre de Huffman\n",
    "    heap = [HuffmanNode(w, f) for w, f in freq.items()]\n",
    "    heapq.heapify(heap)\n",
    "\n",
    "    # Construire l'arbre de Huffman\n",
    "    while len(heap) > 1:\n",
    "        n1 = heapq.heappop(heap)\n",
    "        n2 = heapq.heappop(heap)\n",
    "        merged = HuffmanNode(None, n1.freq + n2.freq)\n",
    "        merged.left, merged.right = n1, n2\n",
    "        heapq.heappush(heap, merged)\n",
    "\n",
    "    # Générer les codes binaires\n",
    "    codes = {}\n",
    "    def generate_codes(node, current=\"\"):\n",
    "        if node is None:\n",
    "            return\n",
    "        if node.char is not None:\n",
    "            codes[node.char] = current\n",
    "        generate_codes(node.left, current + \"0\")\n",
    "        generate_codes(node.right, current + \"1\")\n",
    "\n",
    "    root = heap[0]\n",
    "    generate_codes(root)\n",
    "\n",
    "    # Encoder le texte\n",
    "    encoded = \" \".join(codes[word] for word in words)\n",
    "    return encoded, codes, root  # Retourne aussi l’arbre pour décodage\n",
    "\n",
    "def huffman_decode_words(encoded, root):\n",
    "    decoded_words = []\n",
    "    current = root\n",
    "    for bit in encoded.split():\n",
    "        node = root\n",
    "        for b in bit:\n",
    "            node = node.left if b == '0' else node.right\n",
    "        decoded_words.append(node.char)\n",
    "    return ' '.join(decoded_words)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Byte Pair Encoding (BPE)\n",
    "# -----------------------------\n",
    "def bpe_encode(text, num_merges=50):\n",
    "    text = list(text)\n",
    "    for _ in range(num_merges):\n",
    "        # count pairs\n",
    "        pairs = collections.Counter(zip(text, text[1:]))\n",
    "        if not pairs:\n",
    "            break\n",
    "        best_pair = max(pairs, key=pairs.get)\n",
    "        new_symbol = \"\".join(best_pair)\n",
    "\n",
    "        # replace pair\n",
    "        new_text = []\n",
    "        i = 0\n",
    "        while i < len(text):\n",
    "            if i < len(text) - 1 and (text[i], text[i+1]) == best_pair:\n",
    "                new_text.append(new_symbol)\n",
    "                i += 2\n",
    "            else:\n",
    "                new_text.append(text[i])\n",
    "                i += 1\n",
    "        text = new_text\n",
    "    return text\n",
    "\n",
    "# -----------------------------\n",
    "# 3. LZW compression\n",
    "# -----------------------------\n",
    "def lzw_encode(text):\n",
    "    dict_size = 256\n",
    "    dictionary = {chr(i): i for i in range(dict_size)}\n",
    "\n",
    "    w = \"\"\n",
    "    result = []\n",
    "    for c in text:\n",
    "        wc = w + c\n",
    "        if wc in dictionary:\n",
    "            w = wc\n",
    "        else:\n",
    "            result.append(dictionary[w])\n",
    "            dictionary[wc] = dict_size\n",
    "            dict_size += 1\n",
    "            w = c\n",
    "    if w:\n",
    "        result.append(dictionary[w])\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1bdc567",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lz77_encode(text, window_size=400, lookahead_buffer_size=15):\n",
    "    i = 0\n",
    "    output = []\n",
    "\n",
    "    while i < len(text):\n",
    "        # Fenêtre glissante : zone dans le texte déjà vue\n",
    "        start_window = max(0, i - window_size)\n",
    "        window = text[start_window:i]\n",
    "\n",
    "        # Zone de recherche dans la fenêtre\n",
    "        match_length = 0\n",
    "        match_distance = 0\n",
    "        # Chercher la plus longue correspondance dans la fenêtre\n",
    "        for j in range(len(window)):\n",
    "            length = 0\n",
    "            while (length < lookahead_buffer_size and\n",
    "                   i + length < len(text) and\n",
    "                   window[j + length] == text[i + length]):\n",
    "                length += 1\n",
    "                if j + length >= len(window):\n",
    "                    break\n",
    "            if length > match_length:\n",
    "                match_length = length\n",
    "                match_distance = len(window) - j\n",
    "\n",
    "        if match_length >= 3:\n",
    "            # On encode la séquence répétée\n",
    "            next_char = text[i + match_length] if i + match_length < len(text) else ''\n",
    "            output.append((match_distance, match_length, next_char))\n",
    "            i += match_length + 1\n",
    "        else:\n",
    "            # Pas de correspondance significative : on encode juste le caractère brut\n",
    "            output.append((0, 0, text[i]))\n",
    "            i += 1\n",
    "\n",
    "    return output\n",
    "def estimate_lz77_size(encoded_triplets, bits_offset=9, bits_length=4, bits_char=8):\n",
    "    bits_per_triplet = bits_offset + bits_length + bits_char\n",
    "    total_bits = len(encoded_triplets) * bits_per_triplet\n",
    "    total_bytes = (total_bits + 7) // 8  # round up to nearest byte\n",
    "    return total_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e3a6003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille originale : 4264 caractères\n",
      "Huffman : 2488 octets environ\n",
      "BPE : 1679 symboles (vs 4264 caractères)\n",
      "LZW : 1529 entiers\n",
      "Huffman (mots) : 3693 octets estimés\n",
      "LZ77 : 1284 triplets, taille estimée : 3371 octets\n"
     ]
    }
   ],
   "source": [
    "with open('data/text_code/code1.py') as f:\n",
    "    text = f.read()\n",
    "print(\"Taille originale :\", len(text), \"caractères\")\n",
    "huff_encoded, huff_codes = huffman_encode(text)\n",
    "print(\"Huffman :\", len(huff_encoded) // 8, \"octets environ\")\n",
    "\n",
    "bpe_encoded = bpe_encode(text, num_merges=100)\n",
    "print(\"BPE :\", len(bpe_encoded), \"symboles (vs\", len(text), \"caractères)\")\n",
    "\n",
    "lzw_encoded = lzw_encode(text)\n",
    "print(\"LZW :\", len(lzw_encoded), \"entiers\")\n",
    "\n",
    "encoded, codes, root = huffman_encode_words(text)\n",
    "encoded_length = len(encoded)\n",
    "print(\"Huffman (mots) :\", encoded_length, \"octets estimés\")\n",
    "\n",
    "lz77encoded = lz77_encode(text)\n",
    "lz77_size = estimate_lz77_size(lz77encoded)\n",
    "print(f\"LZ77 : {len(lz77encoded)} triplets, taille estimée : {lz77_size} octets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5cdb718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille originale : 2830 caractères\n",
      "Huffman : 1552 octets environ\n",
      "BPE : 1398 symboles (vs 2830 caractères)\n"
     ]
    }
   ],
   "source": [
    "with open('data/text_natural/text_natural_1.txt') as f:\n",
    "    text = f.read()\n",
    "print(\"Taille originale :\", len(text), \"caractères\")\n",
    "huff_encoded, huff_codes = huffman_encode(text)\n",
    "print(\"Huffman :\", len(huff_encoded) // 8, \"octets environ\")\n",
    "\n",
    "bpe_encoded = bpe_encode(text, num_merges=100)\n",
    "print(\"BPE :\", len(bpe_encoded), \"symboles (vs\", len(text), \"caractères)\")\n",
    "\n",
    "#lzw_encoded = lzw_encode(text)\n",
    "#print(\"LZW :\", len(lzw_encoded), \"entiers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "202f9306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille originale : 4297756 caractères\n",
      "Huffman : 2595917 octets environ\n",
      "LZW : 194363 entiers\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m lzw_encoded = lzw_encode(text)\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLZW :\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(lzw_encoded), \u001b[33m\"\u001b[39m\u001b[33mentiers\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m lz77encoded = \u001b[43mlz77_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m lz77_size = estimate_lz77_size(lz77encoded)\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLZ77 : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(lz77encoded)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m triplets, taille estimée : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlz77_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m octets\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mlz77_encode\u001b[39m\u001b[34m(text, window_size, lookahead_buffer_size)\u001b[39m\n\u001b[32m     20\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m j + length >= \u001b[38;5;28mlen\u001b[39m(window):\n\u001b[32m     21\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m length > match_length:\n\u001b[32m     23\u001b[39m     match_length = length\n\u001b[32m     24\u001b[39m     match_distance = \u001b[38;5;28mlen\u001b[39m(window) - j\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "with open('data/text_structured/accumulation-accounts-2008-2023-provisional.csv') as f:\n",
    "    text = f.read()\n",
    "print(\"Taille originale :\", len(text), \"caractères\")\n",
    "huff_encoded, huff_codes = huffman_encode(text)\n",
    "print(\"Huffman :\", len(huff_encoded) // 8, \"octets environ\")\n",
    "\n",
    "#bpe_encoded = bpe_encode(text, num_merges=100)\n",
    "#print(\"BPE :\", len(bpe_encoded), \"symboles (vs\", len(text), \"caractères)\")\n",
    "\n",
    "lzw_encoded = lzw_encode(text)\n",
    "print(\"LZW :\", len(lzw_encoded), \"entiers\")\n",
    "\n",
    "lz77encoded = lz77_encode(text)\n",
    "lz77_size = estimate_lz77_size(lz77encoded)\n",
    "print(f\"LZ77 : {len(lz77encoded)} triplets, taille estimée : {lz77_size} octets\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
